{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":81655,"databundleVersionId":8915386,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-12T14:58:10.594793Z","iopub.execute_input":"2024-08-12T14:58:10.595684Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"/kaggle/input/cs-480-2024-spring/data/sample_submission.csv\n/kaggle/input/cs-480-2024-spring/data/target_name_meta.tsv\n/kaggle/input/cs-480-2024-spring/data/train.csv\n/kaggle/input/cs-480-2024-spring/data/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# define dataset and model\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.models as torch_models\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\n\n\n# Custom Dataset\nclass PlantDataset(Dataset):\n    def __init__(self, image_paths, ancillary_data, targets, transform=None):\n        self.transform = transform\n        self.images = []\n        for i in range(len(image_paths)): \n            image = Image.open(image_paths[i]).convert('RGB')\n            if self.transform:\n                image = self.transform(image)\n            self.images.append(image)\n        \n        self.ancillary_data = ancillary_data\n        self.targets = targets\n        df = pd.DataFrame([])\n        self.dfType = type(df)\n        if type(self.targets) == self.dfType:\n            self.targets = targets.values\n        id_column = \"id\"\n        self.id_data = self.ancillary_data[id_column]\n        self.id_data = self.id_data.values\n        self.ancillary_data = self.ancillary_data.drop(columns=[id_column])\n        self.ancillary_data = self.ancillary_data.values\n        self.npType = type(self.ancillary_data)\n    \n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        \n        ancillary = self.ancillary_data[idx]\n        target = []\n        if type(self.targets) == self.npType:\n            target = self.targets[idx]\n        image_id = self.id_data[idx]\n        \n        return image, image_id, torch.tensor(ancillary, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)\n    \n\nclass PlantDatasetUnloaded(Dataset):\n    def __init__(self, image_paths, ancillary_data, targets, transform=None):\n        self.transform = transform\n        self.image_paths = image_paths\n        \n        self.ancillary_data = ancillary_data\n        self.targets = targets\n        df = pd.DataFrame([])\n        self.dfType = type(df)\n        if type(self.targets) == self.dfType:\n            self.targets = targets.values\n        id_column = \"id\"\n        self.id_data = self.ancillary_data[id_column]\n        self.id_data = self.id_data.values\n        self.ancillary_data = self.ancillary_data.drop(columns=[id_column])\n        self.ancillary_data = self.ancillary_data.values\n        self.npType = type(self.ancillary_data)\n    \n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.image_paths[i]).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        \n        ancillary = self.ancillary_data[idx]\n        target = []\n        if type(self.targets) == self.npType:\n            target = self.targets[idx]\n        image_id = self.id_data[idx]\n        \n        return image, image_id, torch.tensor(ancillary, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)\n\n        \n# Model Definition\nclass PlantModel(nn.Module):\n    def __init__(self, output_size, resnet_feature_size, ancillary_feature_size):\n        super(PlantModel, self).__init__()\n        self.output_size = output_size\n        self.resnet = torch_models.resnet50(weights=torch_models.ResNet50_Weights.DEFAULT)\n        # Freeze all layers\n#         for param in self.resnet.parameters():\n#             param.requires_grad = False\n#         for param in self.resnet.fc.parameters(): \n#             param.requires_grad = True\n#         for param in self.resnet.layer4.parameters(): \n#             param.requires_grad = True\n        \n\n        # Replace the final fully connected layer\n        num_features = self.resnet.fc.in_features\n        self.resnet.fc = nn.Linear(num_features, resnet_feature_size)  # num_classes is the number of output classes\n        \n        self.fc1 = nn.Linear(resnet_feature_size + ancillary_feature_size, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 128)  \n        self.fc4 = nn.Linear(128, self.output_size)\n        \n        self.dropout1 = nn.Dropout(p=0.5)\n        self.dropout2 = nn.Dropout(p=0.5)\n        self.dropout3 = nn.Dropout(p=0.5)\n        \n        self.activation1 = nn.ReLU()\n        self.activation2 = nn.ReLU()\n        self.activation3 = nn.ReLU()\n        \n\n    def forward(self, image, ancillary):\n        image_features = self.resnet(image)\n        x = torch.cat((image_features, ancillary), dim=1)\n        x = self.activation1(self.fc1(x))\n        x = self.dropout1(x)\n        x = self.activation2(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.activation3(self.fc3(x))\n        x = self.dropout3(x)\n        x = self.fc4(x)\n        return x\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/cs-480-2024-spring/data/train.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_outliers_zscore(df, id_column, threshold=3):\n    \"\"\"\n    Remove outliers from a dataset using the Z-score method.\n\n    Parameters:\n    - df: pandas DataFrame containing the dataset.\n    - threshold: Z-score threshold for identifying outliers.\n\n    Returns:\n    - df_clean: DataFrame with outliers removed.\n    \"\"\"\n    z_scores = np.abs((df - df.mean()) / df.std())\n    z_scores[id_column] = 0\n    z_scores.iloc[:, -6:] = 0\n    df_clean = df[(z_scores < threshold).all(axis=1)]\n    return df_clean","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove outliers and split into ancillary data and targets\ntrain_df = remove_outliers_zscore(train_df, \"id\")\ntrain_ancillary_data = train_df.iloc[:, :-6]\ntrain_targets = train_df.iloc[:, -6:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize targets using min max scaling\nmin_target_val = train_targets.min()\nmax_target_val = train_targets.max()\n\nnormalized_train_targets = (\n    (train_targets - min_target_val) / (max_target_val - min_target_val)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize ancillary training data (excluding the id column) using min max scaling \nid_column = \"id\"\nid_data = train_ancillary_data[id_column]\ntrain_ancillary_data = train_ancillary_data.drop(columns=[id_column])\nmin_val = train_ancillary_data.min()\nmax_val = train_ancillary_data.max()\n\nnormalized_train_ancillary_data = (\n    (train_ancillary_data - min_val) / (max_val - min_val)\n)\nnormalized_train_ancillary_data[id_column] = id_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get training image paths\ntrain_images_dir = \"/kaggle/input/cs-480-2024-spring/data/train_images\"\ntest_images_dir = \"/kaggle/input/cs-480-2024-spring/data/test_images\"\n\ntrain_image_paths = []\ntest_image_paths = []\nfor i in range(len(normalized_train_ancillary_data)): \n    image_id = int(normalized_train_ancillary_data.iloc[i].id)\n    filename = str(image_id) + \".jpeg\"\n    path = os.path.join(train_images_dir, filename)\n    train_image_paths.append(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize training dataset and dataloader\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(30),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_dataset = PlantDataset(\n    train_image_paths, normalized_train_ancillary_data, \n    normalized_train_targets, transform=transform\n)\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the model\nfrom sklearn.metrics import r2_score\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"device = \", device)\noutput_size = 6\nmodel = PlantModel(\n    output_size, \n    resnet_feature_size=2048, \n    ancillary_feature_size=163\n).to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nimport matplotlib.pyplot as plt\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# R2 Score Function\ndef calculate_r2_score(y_true, y_pred):\n    y_true = y_true.detach().cpu().numpy()\n    y_pred = y_pred.detach().cpu().numpy()\n    return r2_score(y_true, y_pred)\n\nnum_epochs = 1\nr2_epoch_scores = []\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    r2_scores = []\n    for idx, data in enumerate(train_dataloader):\n        images, image_ids, ancillary_data, targets = data\n        images, ancillary_data, targets = images.to(device), ancillary_data.to(device), targets.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images, ancillary_data)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n        batch_r2 = calculate_r2_score(targets, outputs)\n\n        r2_scores.append(batch_r2)\n        if idx % 100 == 0: \n            mean_loss = running_loss / (idx + 1)\n            mean_r2_score = np.mean(r2_scores)\n            print(idx, mean_loss, mean_r2_score)\n    \n    epoch_loss = running_loss / len(train_dataloader)\n    epoch_r2 = np.mean(r2_scores)\n    r2_epoch_scores.append(epoch_r2)\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, R2 Score: {epoch_r2:.4f}')\n\nplt.plot(r2_epoch_scores)\nprint(\"Training complete\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load and preprocess test data\ntest_ancillary_data = pd.read_csv(\"/kaggle/input/cs-480-2024-spring/data/test.csv\")\nid_column = \"id\"\ntest_id_data = test_ancillary_data[id_column]\ntest_ancillary_data = test_ancillary_data.drop(columns=[id_column])\n\nnormalized_test_ancillary_data = (\n    (test_ancillary_data - min_val) / (max_val - min_val)\n)\nnormalized_test_ancillary_data[id_column] = test_id_data \n\ntest_image_paths = []\nfor i in range(len(normalized_test_ancillary_data)): \n    image_id = int(normalized_test_ancillary_data.iloc[i].id)\n    filename = str(image_id) + \".jpeg\"\n    path = os.path.join(test_images_dir, filename)\n    test_image_paths.append(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize test dataset and dataloader\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntest_dataset = PlantDatasetUnloaded(\n    test_image_paths, normalized_test_ancillary_data, \n    None, transform=test_transform\n)\ntest_dataloader = DataLoader(ensemble_test_dataset, batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions and save them in csv\npredictions = []\nids = []\n\nmodel.eval()\nwith torch.no_grad():\n    for images, id_batch, ancillary_data, _ in test_dataloader:\n        images, ancillary_data = images.to(device), ancillary_data.to(device)\n        \n        pred_batch = model(images, ancillary_data)\n        pred_batch = pred_batch.cpu().numpy()\n        # unscale preds\n        for pred in pred_batch:\n            pred = (pred * (max_target_val - min_target_val)) + min_target_val\n            predictions.append(pred)\n        ids.extend(id_batch.numpy())\n\n# Save predictions to CSV\n\ncol_labels = train_df.iloc[:, -6:].columns.values\npredictions_df = pd.DataFrame(predictions, columns=col_labels)\npredictions_df.insert(0, 'id', ids)\npredictions_df.to_csv('predictions.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
